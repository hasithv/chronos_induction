{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-25 10:59:45,313] [WARNING] [real_accelerator.py:194:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2025-05-25 10:59:45,318] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from chronos import BaseChronosPipeline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import rrt_utils as rrt\n",
    "import attn_lens as attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rrt_induction_data(\n",
    "    vocab_range=(1911, 2187),\n",
    "    batch_size=100,\n",
    "    num_unique_sequences=1,\n",
    "    repeat_factor=4,\n",
    "    extension=0,\n",
    "    sub_extension=1,\n",
    "    sequence_length=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate data for RRT induction experiments.\n",
    "    \n",
    "    Args:\n",
    "        vocab_range: Tuple of (min, max) vocab indices to use\n",
    "        batch_size: Number of sequences in the batch\n",
    "        num_unique_sequences: Number of unique sequences in the batch\n",
    "        repeat_factor: Number of times to repeat the sequences\n",
    "        extension: After repeating everything, repeat this many sequences again\n",
    "        sub_extension: Some additional tokens in the next sequence\n",
    "        sequence_length: Length of each sequence\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (token_ids, attention_mask, decoder_input_ids)\n",
    "    \"\"\"\n",
    "    # Define the vocab as all the tokens within the specified range\n",
    "    vocab = torch.tensor([i for i in range(4096) if i >= vocab_range[0] and i <= vocab_range[1]])\n",
    "    \n",
    "    # Generate random token sequences\n",
    "    tokens = [rrt.generate_random_token_ids(vocab, sequence_length, batch_size=batch_size, include_eos=False) \n",
    "              for _ in range(num_unique_sequences)]\n",
    "    \n",
    "    # Stack sequences with repetition pattern\n",
    "    token_ids = rrt.stack_sequences(tokens * repeat_factor + tokens[:extension] + [tokens[extension][:,:sub_extension]])\n",
    "    \n",
    "    # Create attention mask\n",
    "    attention_mask = torch.ones_like(token_ids, dtype=torch.bool)\n",
    "    \n",
    "    # Create decoder input ids\n",
    "    decoder_input_ids = torch.cat([\n",
    "        torch.zeros((batch_size, 1), dtype=torch.long), \n",
    "        tokens[extension][:,sub_extension:sub_extension+1]\n",
    "    ], dim=1)\n",
    "    \n",
    "    return token_ids, attention_mask, decoder_input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repeat_factor=2, sequence_length=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids.shape: torch.Size([100, 6]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf2_sl2...\n",
      "Processing amazon/chronos-t5-small for rf2_sl2...\n",
      "Processing amazon/chronos-t5-base for rf2_sl2...\n",
      "Processing amazon/chronos-t5-large for rf2_sl2...\n",
      "Processing repeat_factor=2, sequence_length=4\n",
      "token_ids.shape: torch.Size([100, 10]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf2_sl4...\n",
      "Processing amazon/chronos-t5-small for rf2_sl4...\n",
      "Processing amazon/chronos-t5-base for rf2_sl4...\n",
      "Processing amazon/chronos-t5-large for rf2_sl4...\n",
      "Processing repeat_factor=2, sequence_length=6\n",
      "token_ids.shape: torch.Size([100, 14]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf2_sl6...\n",
      "Processing amazon/chronos-t5-small for rf2_sl6...\n",
      "Processing amazon/chronos-t5-base for rf2_sl6...\n",
      "Processing amazon/chronos-t5-large for rf2_sl6...\n",
      "Processing repeat_factor=2, sequence_length=8\n",
      "token_ids.shape: torch.Size([100, 18]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf2_sl8...\n",
      "Processing amazon/chronos-t5-small for rf2_sl8...\n",
      "Processing amazon/chronos-t5-base for rf2_sl8...\n",
      "Processing amazon/chronos-t5-large for rf2_sl8...\n",
      "Processing repeat_factor=2, sequence_length=10\n",
      "token_ids.shape: torch.Size([100, 22]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf2_sl10...\n",
      "Processing amazon/chronos-t5-small for rf2_sl10...\n",
      "Processing amazon/chronos-t5-base for rf2_sl10...\n",
      "Processing amazon/chronos-t5-large for rf2_sl10...\n",
      "Processing repeat_factor=4, sequence_length=2\n",
      "token_ids.shape: torch.Size([100, 10]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf4_sl2...\n",
      "Processing amazon/chronos-t5-small for rf4_sl2...\n",
      "Processing amazon/chronos-t5-base for rf4_sl2...\n",
      "Processing amazon/chronos-t5-large for rf4_sl2...\n",
      "Processing repeat_factor=4, sequence_length=4\n",
      "token_ids.shape: torch.Size([100, 18]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf4_sl4...\n",
      "Processing amazon/chronos-t5-small for rf4_sl4...\n",
      "Processing amazon/chronos-t5-base for rf4_sl4...\n",
      "Processing amazon/chronos-t5-large for rf4_sl4...\n",
      "Processing repeat_factor=4, sequence_length=6\n",
      "token_ids.shape: torch.Size([100, 26]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf4_sl6...\n",
      "Processing amazon/chronos-t5-small for rf4_sl6...\n",
      "Processing amazon/chronos-t5-base for rf4_sl6...\n",
      "Processing amazon/chronos-t5-large for rf4_sl6...\n",
      "Processing repeat_factor=4, sequence_length=8\n",
      "token_ids.shape: torch.Size([100, 34]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf4_sl8...\n",
      "Processing amazon/chronos-t5-small for rf4_sl8...\n",
      "Processing amazon/chronos-t5-base for rf4_sl8...\n",
      "Processing amazon/chronos-t5-large for rf4_sl8...\n",
      "Processing repeat_factor=4, sequence_length=10\n",
      "token_ids.shape: torch.Size([100, 42]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf4_sl10...\n",
      "Processing amazon/chronos-t5-small for rf4_sl10...\n",
      "Processing amazon/chronos-t5-base for rf4_sl10...\n",
      "Processing amazon/chronos-t5-large for rf4_sl10...\n",
      "Processing repeat_factor=6, sequence_length=2\n",
      "token_ids.shape: torch.Size([100, 14]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf6_sl2...\n",
      "Processing amazon/chronos-t5-small for rf6_sl2...\n",
      "Processing amazon/chronos-t5-base for rf6_sl2...\n",
      "Processing amazon/chronos-t5-large for rf6_sl2...\n",
      "Processing repeat_factor=6, sequence_length=4\n",
      "token_ids.shape: torch.Size([100, 26]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf6_sl4...\n",
      "Processing amazon/chronos-t5-small for rf6_sl4...\n",
      "Processing amazon/chronos-t5-base for rf6_sl4...\n",
      "Processing amazon/chronos-t5-large for rf6_sl4...\n",
      "Processing repeat_factor=6, sequence_length=6\n",
      "token_ids.shape: torch.Size([100, 38]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf6_sl6...\n",
      "Processing amazon/chronos-t5-small for rf6_sl6...\n",
      "Processing amazon/chronos-t5-base for rf6_sl6...\n",
      "Processing amazon/chronos-t5-large for rf6_sl6...\n",
      "Processing repeat_factor=6, sequence_length=8\n",
      "token_ids.shape: torch.Size([100, 50]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf6_sl8...\n",
      "Processing amazon/chronos-t5-small for rf6_sl8...\n",
      "Processing amazon/chronos-t5-base for rf6_sl8...\n",
      "Processing amazon/chronos-t5-large for rf6_sl8...\n",
      "Processing repeat_factor=6, sequence_length=10\n",
      "token_ids.shape: torch.Size([100, 62]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf6_sl10...\n",
      "Processing amazon/chronos-t5-small for rf6_sl10...\n",
      "Processing amazon/chronos-t5-base for rf6_sl10...\n",
      "Processing amazon/chronos-t5-large for rf6_sl10...\n",
      "Processing repeat_factor=8, sequence_length=2\n",
      "token_ids.shape: torch.Size([100, 18]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf8_sl2...\n",
      "Processing amazon/chronos-t5-small for rf8_sl2...\n",
      "Processing amazon/chronos-t5-base for rf8_sl2...\n",
      "Processing amazon/chronos-t5-large for rf8_sl2...\n",
      "Processing repeat_factor=8, sequence_length=4\n",
      "token_ids.shape: torch.Size([100, 34]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf8_sl4...\n",
      "Processing amazon/chronos-t5-small for rf8_sl4...\n",
      "Processing amazon/chronos-t5-base for rf8_sl4...\n",
      "Processing amazon/chronos-t5-large for rf8_sl4...\n",
      "Processing repeat_factor=8, sequence_length=6\n",
      "token_ids.shape: torch.Size([100, 50]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf8_sl6...\n",
      "Processing amazon/chronos-t5-small for rf8_sl6...\n",
      "Processing amazon/chronos-t5-base for rf8_sl6...\n",
      "Processing amazon/chronos-t5-large for rf8_sl6...\n",
      "Processing repeat_factor=8, sequence_length=8\n",
      "token_ids.shape: torch.Size([100, 66]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf8_sl8...\n",
      "Processing amazon/chronos-t5-small for rf8_sl8...\n",
      "Processing amazon/chronos-t5-base for rf8_sl8...\n",
      "Processing amazon/chronos-t5-large for rf8_sl8...\n",
      "Processing repeat_factor=8, sequence_length=10\n",
      "token_ids.shape: torch.Size([100, 82]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf8_sl10...\n",
      "Processing amazon/chronos-t5-small for rf8_sl10...\n",
      "Processing amazon/chronos-t5-base for rf8_sl10...\n",
      "Processing amazon/chronos-t5-large for rf8_sl10...\n",
      "Processing repeat_factor=10, sequence_length=2\n",
      "token_ids.shape: torch.Size([100, 22]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf10_sl2...\n",
      "Processing amazon/chronos-t5-small for rf10_sl2...\n",
      "Processing amazon/chronos-t5-base for rf10_sl2...\n",
      "Processing amazon/chronos-t5-large for rf10_sl2...\n",
      "Processing repeat_factor=10, sequence_length=4\n",
      "token_ids.shape: torch.Size([100, 42]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf10_sl4...\n",
      "Processing amazon/chronos-t5-small for rf10_sl4...\n",
      "Processing amazon/chronos-t5-base for rf10_sl4...\n",
      "Processing amazon/chronos-t5-large for rf10_sl4...\n",
      "Processing repeat_factor=10, sequence_length=6\n",
      "token_ids.shape: torch.Size([100, 62]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf10_sl6...\n",
      "Processing amazon/chronos-t5-small for rf10_sl6...\n",
      "Processing amazon/chronos-t5-base for rf10_sl6...\n",
      "Processing amazon/chronos-t5-large for rf10_sl6...\n",
      "Processing repeat_factor=10, sequence_length=8\n",
      "token_ids.shape: torch.Size([100, 82]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf10_sl8...\n",
      "Processing amazon/chronos-t5-small for rf10_sl8...\n",
      "Processing amazon/chronos-t5-base for rf10_sl8...\n",
      "Processing amazon/chronos-t5-large for rf10_sl8...\n",
      "Processing repeat_factor=10, sequence_length=10\n",
      "token_ids.shape: torch.Size([100, 102]), decoder_input_ids.shape: torch.Size([100, 2])\n",
      "Processing amazon/chronos-t5-mini for rf10_sl10...\n",
      "Processing amazon/chronos-t5-small for rf10_sl10...\n",
      "Processing amazon/chronos-t5-base for rf10_sl10...\n",
      "Processing amazon/chronos-t5-large for rf10_sl10...\n"
     ]
    }
   ],
   "source": [
    "# Define different values to experiment with\n",
    "repeat_factors = [2, 4, 6, 8, 10]\n",
    "sequence_lengths = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Initialize dictionaries to store results for different configurations\n",
    "all_results = {}\n",
    "\n",
    "model_names = [\"amazon/chronos-t5-mini\", \"amazon/chronos-t5-small\", \"amazon/chronos-t5-base\", \"amazon/chronos-t5-large\"]\n",
    "\n",
    "for repeat_factor in repeat_factors:\n",
    "    for sequence_length in sequence_lengths:\n",
    "        print(f\"Processing repeat_factor={repeat_factor}, sequence_length={sequence_length}\")\n",
    "        \n",
    "        num_unique_sequences = 1  # number of unique sequences in the batch\n",
    "        extension = 0  # after repeating everything, repeat this many sequences again\n",
    "        sub_extension = 1  # some additional tokens in the next sequence\n",
    "        \n",
    "        # Generate data with current configuration\n",
    "        token_ids, attention_mask, decoder_input_ids = generate_rrt_induction_data(\n",
    "            num_unique_sequences=num_unique_sequences, \n",
    "            repeat_factor=repeat_factor, \n",
    "            extension=extension, \n",
    "            sub_extension=sub_extension, \n",
    "            sequence_length=sequence_length\n",
    "        )\n",
    "        \n",
    "        # Display shapes and sample values\n",
    "        print(f\"token_ids.shape: {token_ids.shape}, decoder_input_ids.shape: {decoder_input_ids.shape}\")\n",
    "        \n",
    "        # Store results for each model\n",
    "        config_key = f\"rf{repeat_factor}_sl{sequence_length}\"\n",
    "        all_results[config_key] = {\n",
    "            \"center_scores\": {},\n",
    "            \"right_scores\": {}\n",
    "        }\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            print(f\"Processing {model_name} for {config_key}...\")\n",
    "            \n",
    "            pipeline = BaseChronosPipeline.from_pretrained(\n",
    "                model_name,  # use \"amazon/chronos-bolt-small\" for the corresponding Chronos-Bolt model\n",
    "                device_map=\"cpu\",  # use \"cpu\" for CPU inference\n",
    "                torch_dtype=torch.bfloat16,\n",
    "            )\n",
    "\n",
    "            if \"bolt\" in model_name:\n",
    "                t5_model = pipeline.model\n",
    "            else:\n",
    "                t5_model = pipeline.model.model\n",
    "\n",
    "            outputs = t5_model.generate(\n",
    "                input_ids=token_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=1,\n",
    "                decoder_input_ids=decoder_input_ids,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=False,\n",
    "                use_cache=False,\n",
    "                output_attentions=True,\n",
    "                output_scores=True,\n",
    "                output_hidden_states=True,\n",
    "                return_dict_in_generate=True\n",
    "            )\n",
    "            \n",
    "            # Extract cross attention probabilities\n",
    "            # cross_attentions is a list of length layers, each with shape [batch, heads, dec_length, enc_length]\n",
    "            cross_attn_probs = outputs.cross_attentions\n",
    "            \n",
    "            t_idx = 1\n",
    "            s_idx = sequence_length * ((repeat_factor-1)*num_unique_sequences + extension) + sub_extension\n",
    "\n",
    "            layers, heads = t5_model.config.num_decoder_layers, t5_model.config.num_heads\n",
    "            mosaic_center = np.zeros((layers, heads)).tolist()\n",
    "            mosaic_right = np.zeros((layers, heads)).tolist()\n",
    "\n",
    "            for layer in range(layers):\n",
    "                for head in range(heads):\n",
    "                    # mean over the batch\n",
    "                    mosaic_center[layer][head] = float(cross_attn_probs[0][layer][:, head, t_idx, s_idx].mean())\n",
    "                    mosaic_right[layer][head] = float(cross_attn_probs[0][layer][:, head, t_idx, s_idx+1].mean())\n",
    "            \n",
    "            # Store the scores for this model and configuration\n",
    "            all_results[config_key][\"center_scores\"][model_name] = mosaic_center\n",
    "            all_results[config_key][\"right_scores\"][model_name] = mosaic_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.makedirs(\"variables\", exist_ok=True)\n",
    "with open(\"variables/results.json\", \"w\") as f:\n",
    "    json.dump(all_results, f)\n",
    "\n",
    "# load the results\n",
    "with open(\"variables/results.json\", \"r\") as f:\n",
    "    all_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5189fc9ad34ddf842e8004b4e5c0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Repeat Factor:', index=1, options=(2, 4, 6, 8, 10), value=4), Dropdown(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a8cfdda5094bdaa80452a618a5defd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0.00052642822265625,
           0.0400390625,
           0.04248046875,
           0.10498046875,
           0.16796875,
           0.039306640625,
           0.458984375,
           0.038330078125
          ],
          [
           0.052734375,
           0.033203125,
           0.61328125,
           0.047119140625,
           0.0849609375,
           0.03564453125,
           0.049560546875,
           0.050537109375
          ],
          [
           0.205078125,
           0.053466796875,
           0.036376953125,
           0.061279296875,
           0.042724609375,
           0.03662109375,
           0.123046875,
           0.040283203125
          ],
          [
           0.0361328125,
           0.0390625,
           0.0458984375,
           0.044921875,
           0.037841796875,
           0.03271484375,
           0.034912109375,
           0.034912109375
          ]
         ],
         "zmax": 1,
         "zmin": 0
        },
        {
         "coloraxis": "coloraxis",
         "type": "heatmap",
         "xaxis": "x2",
         "yaxis": "y2",
         "z": [
          [
           0.000606536865234375,
           0.04638671875,
           0.0498046875,
           0.02685546875,
           0.0294189453125,
           0.0458984375,
           0.0032196044921875,
           0.03271484375
          ],
          [
           0.043701171875,
           0.06005859375,
           0.0147705078125,
           0.04931640625,
           0.203125,
           0.045166015625,
           0.0478515625,
           0.04931640625
          ],
          [
           0.04541015625,
           0.07763671875,
           0.17578125,
           0.1806640625,
           0.10302734375,
           0.07861328125,
           0.04931640625,
           0.055419921875
          ],
          [
           0.1435546875,
           0.0634765625,
           0.048095703125,
           0.119140625,
           0.053466796875,
           0.0869140625,
           0.1455078125,
           0.12353515625
          ]
         ],
         "zmax": 1,
         "zmin": 0
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Current token",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Token to right of current",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "coloraxis": {
         "cmax": 1,
         "cmin": 0,
         "colorbar": {
          "title": {
           "text": "Attention Score"
          }
         }
        },
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Attention Mosaics For Induction on RRTs - RF: 2, SL: 10, Model: chronos-t5-mini"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "dtick": 1,
         "showticklabels": true,
         "tick0": 0,
         "tickmode": "linear",
         "title": {
          "font": {
           "size": 18
          },
          "text": "Head"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "dtick": 1,
         "showticklabels": true,
         "tick0": 0,
         "tickmode": "linear",
         "title": {
          "font": {
           "size": 18
          },
          "text": "Head"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "dtick": 1,
         "showticklabels": true,
         "tick0": 0,
         "tickmode": "linear",
         "title": {
          "font": {
           "size": 18
          },
          "text": "Layer"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "dtick": 1,
         "matches": "y",
         "showticklabels": true,
         "tick0": 0,
         "tickmode": "linear",
         "title": {
          "font": {
           "size": 18
          },
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7b181520a74571b10a3403e5cb8a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Current Figure', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = [2, 4, 6, 8, 10]\n",
    "sl = [2, 4, 6, 8, 10]\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create widgets for configuration selection\n",
    "rf_dropdown = widgets.Dropdown(\n",
    "    options=rf,\n",
    "    value=4,\n",
    "    description='Repeat Factor:'\n",
    ")\n",
    "\n",
    "sl_dropdown = widgets.Dropdown(\n",
    "    options=sl,\n",
    "    value=10,\n",
    "    description='Sequence Length:'\n",
    ")\n",
    "\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=model_names,\n",
    "    value=model_names[0],\n",
    "    description='Model:'\n",
    ")\n",
    "\n",
    "# Create output widget to display the plots\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define the update function\n",
    "def update_plot(change=None):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        \n",
    "        # Get current selections\n",
    "        current_rf = rf_dropdown.value\n",
    "        current_sl = sl_dropdown.value\n",
    "        current_model = model_dropdown.value\n",
    "        \n",
    "        # Generate config key\n",
    "        config_key = f\"rf{current_rf}_sl{current_sl}\"\n",
    "        \n",
    "        # Check if config exists in results\n",
    "        if config_key not in all_results:\n",
    "            print(f\"No data available for configuration: {config_key}\")\n",
    "            return\n",
    "        \n",
    "        # Get scores for current configuration\n",
    "        all_center_scores = all_results[config_key][\"center_scores\"]\n",
    "        all_right_scores = all_results[config_key][\"right_scores\"]\n",
    "        \n",
    "        # Check if model exists in scores\n",
    "        if current_model not in all_center_scores or current_model not in all_right_scores:\n",
    "            print(f\"No data available for model {current_model} with configuration {config_key}\")\n",
    "            return\n",
    "        \n",
    "        # Get data for current model\n",
    "        mosaic_center = all_center_scores[current_model]\n",
    "        mosaic_right = all_right_scores[current_model]\n",
    "        \n",
    "        # Create a subplot with 2 side-by-side heatmaps\n",
    "        fig = make_subplots(rows=1, cols=2, \n",
    "                            subplot_titles=(\"Current token\", \"Token to right of current\"),\n",
    "                            shared_yaxes=True)\n",
    "\n",
    "        # Add heatmaps to the subplots\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(z=mosaic_center, zmin=0, zmax=1, coloraxis=\"coloraxis\"),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(z=mosaic_right, zmin=0, zmax=1, coloraxis=\"coloraxis\"),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title_text=f\"Attention Mosaics For Induction on RRTs - RF: {current_rf}, SL: {current_sl}, Model: {current_model.split('/')[-1]}\",\n",
    "            height=500,\n",
    "            width=1000,\n",
    "            coloraxis=dict(cmin=0, cmax=1, colorbar=dict(title=\"Attention Score\"))\n",
    "        )\n",
    "\n",
    "        # Add axes labels with integer ticks\n",
    "        fig.update_xaxes(title_text=\"Head\", row=1, col=1, title_font=dict(size=18), \n",
    "                        tickmode='linear', tick0=0, dtick=1, showticklabels=True)\n",
    "        fig.update_xaxes(title_text=\"Head\", row=1, col=2, title_font=dict(size=18), \n",
    "                        tickmode='linear', tick0=0, dtick=1, showticklabels=True)\n",
    "        fig.update_yaxes(title_text=\"Layer\", row=1, col=1, title_font=dict(size=18), \n",
    "                        tickmode='linear', tick0=0, dtick=1, showticklabels=True)\n",
    "        fig.update_yaxes(title_text=\"Layer\", row=1, col=2, title_font=dict(size=18), \n",
    "                        tickmode='linear', tick0=0, dtick=1, showticklabels=True)\n",
    "\n",
    "        # Show the figure\n",
    "        fig.show()\n",
    "\n",
    "# Register the update function with the widgets\n",
    "rf_dropdown.observe(update_plot, names='value')\n",
    "sl_dropdown.observe(update_plot, names='value')\n",
    "model_dropdown.observe(update_plot, names='value')\n",
    "\n",
    "# Create a container for the controls\n",
    "controls = widgets.HBox([rf_dropdown, sl_dropdown, model_dropdown])\n",
    "\n",
    "# Display widgets and initial plot\n",
    "display(controls)\n",
    "display(output)\n",
    "\n",
    "# Show initial plot\n",
    "update_plot()\n",
    "\n",
    "# Function to save current figure\n",
    "def save_current_figure():\n",
    "    current_rf = rf_dropdown.value\n",
    "    current_sl = sl_dropdown.value\n",
    "    current_model = model_dropdown.value\n",
    "    \n",
    "    config_key = f\"rf{current_rf}_sl{current_sl}\"\n",
    "    \n",
    "    if config_key not in all_results:\n",
    "        print(f\"No data available for configuration: {config_key}\")\n",
    "        return\n",
    "    \n",
    "    all_center_scores = all_results[config_key][\"center_scores\"]\n",
    "    all_right_scores = all_results[config_key][\"right_scores\"]\n",
    "    \n",
    "    if current_model not in all_center_scores or current_model not in all_right_scores:\n",
    "        print(f\"No data available for model {current_model} with configuration {config_key}\")\n",
    "        return\n",
    "    \n",
    "    mosaic_center = all_center_scores[current_model]\n",
    "    mosaic_right = all_right_scores[current_model]\n",
    "    \n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                      subplot_titles=(\"Current token\", \"Token to right of current\"),\n",
    "                      shared_yaxes=True)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(z=mosaic_center, zmin=0, zmax=1, coloraxis=\"coloraxis\"),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(z=mosaic_right, zmin=0, zmax=1, coloraxis=\"coloraxis\"),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Attention Mosaics For Induction on RRTs - RF: {current_rf}, SL: {current_sl}, Model: {current_model.split('/')[-1]}\",\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        coloraxis=dict(cmin=0, cmax=1, colorbar=dict(title=\"Attention Score\"))\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Head\", row=1, col=1, title_font=dict(size=18), \n",
    "                   tickmode='linear', tick0=0, dtick=1, showticklabels=True)\n",
    "    fig.update_xaxes(title_text=\"Head\", row=1, col=2, title_font=dict(size=18), \n",
    "                   tickmode='linear', tick0=0, dtick=1, showticklabels=True)\n",
    "    fig.update_yaxes(title_text=\"Layer\", row=1, col=1, title_font=dict(size=18), \n",
    "                   tickmode='linear', tick0=0, dtick=1, showticklabels=True)\n",
    "    fig.update_yaxes(title_text=\"Layer\", row=1, col=2, title_font=dict(size=18), \n",
    "                   tickmode='linear', tick0=0, dtick=1, showticklabels=True)\n",
    "    \n",
    "    # manually convert any numpy arrays to lists\n",
    "    for trace in fig.data:\n",
    "        if isinstance(trace.z, np.ndarray):\n",
    "            trace.z = trace.z.tolist()\n",
    "        if hasattr(trace, \"x\") and isinstance(trace.x, np.ndarray):\n",
    "            trace.x = trace.x.tolist()\n",
    "        if hasattr(trace, \"y\") and isinstance(trace.y, np.ndarray):\n",
    "            trace.y = trace.y.tolist()\n",
    "    \n",
    "    os.makedirs(\"plots/json\", exist_ok=True)\n",
    "    output_png_filename = f\"plots/rf{current_rf}_sl{current_sl}_{current_model.split('/')[-1]}\"\n",
    "    output_json_filename = f\"plots/json/rf{current_rf}_sl{current_sl}_{current_model.split('/')[-1]}\"\n",
    "    \n",
    "    fig.write_image(f\"{output_png_filename}.png\")\n",
    "    print(f\"Saved figure to {output_png_filename}.png\")\n",
    "\n",
    "# Create save button\n",
    "save_button = widgets.Button(\n",
    "    description='Save Current Figure',\n",
    "    button_style='success'\n",
    ")\n",
    "save_button.on_click(lambda b: save_current_figure())\n",
    "display(save_button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chronos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
